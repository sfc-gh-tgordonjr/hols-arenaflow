{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "4tyafd6m27bmvkwelzgy",
   "authorId": "6681083712487",
   "authorName": "TGORDONJR",
   "authorEmail": "tony.gordonjr@snowflake.com",
   "sessionId": "c30b1e6f-971d-4867-91cc-22b7f5331f59",
   "lastEditTime": 1749233872552
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "name": "OVERVIEW"
   },
   "source": [
    "## What You'll Learn Today\n",
    "\n",
    "Welcome to ArenaFlow Intelligence Hub!  Throughout this lab you'll see how easy it is to integrate Cortex AI into Snowflake's core data engineering features to batch process unstructured data.\n",
    "\n",
    "We'll highlight several Snowflake features to throughout this lab:\n",
    "- [Snowflake Cortex](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions)\n",
    "    - Task Specific Functions for analyzing sentiment and summarization\n",
    "    - Cortex Complete to generate a prompt and response \n",
    "- [Snowflake Notebooks on Container Runtime](https://docs.snowflake.com/en/developer-guide/snowflake-ml/notebooks-on-spcs)\n",
    "    - Execute the notebook on a GPU powered compute pool\n",
    "    - Leverage a pre-built image containing hundreds of common Python packages\n",
    "    - Create an external access integration to install additional 3rd party Python packages\n",
    "- [Triggered tasks](https://docs.snowflake.com/en/user-guide/tasks-intro#triggered-tasks)\n",
    "    - Process data based on specific data change events\n",
    "- [Dynamic Tables](https://docs.snowflake.com/en/user-guide/dynamic-tables-intro)\n",
    "    - Incrementally process changed data\n",
    "- [Cortex Analyst](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst)\n",
    "    - Create a chat applications for a \"talk to your data\" experience\n",
    "- [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)\n",
    "    - Host your Cortex Analyst chat app directly within Snowsight\n",
    "\n",
    "## Lab Setting\n",
    "Picture this: a packed stadium, fans buzzing, the air thick with excitement and every second, tweets are flying about the game, the food, the vibe. The ArenaFlow Intelligence Hub grabs that chaos and turns it into gold. This platform’s your real-time window into what’s happening, analyzing fan tweets on the fly to tell you what’s hot, what’s not, and where to step up your game, all refreshed every minute.\n",
    "\n",
    "Snowflake’s Cortex AI functions are the MVPs here. They’re like your personal opportunity scoping crew, decoding the mood of every tweet, summing up the chatter, and flagging trends faster than you can say “touchdown.” Stadium bosses get the scoop to act quick and send staff to a jammed concession or amplify a player’s epic moment to keep the crowd roaring. It’s your sixth sense for the stadium, turning raw data into a live playbook for better experiences, smoother ops, and smarter moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "pip_install"
   },
   "outputs": [],
   "source": [
    "!pip install fake_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f54f6b-2dd7-4be4-9929-9ba4a9a0aa19",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "# standard python packages\nimport json\nimport random\nfrom pprint import pprint\nfrom datetime import datetime, timezone\nfrom typing import Union\n\n\n# package for generating fake tweets\nfrom fake_profile import Xprofile\n\n# parallel execution\nfrom concurrent.futures import ThreadPoolExecutor\nimport asyncio\n\n# snowflake packages\nfrom snowflake.snowpark.context import get_active_session"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b5331-418d-4514-92d2-1fedfba11521",
   "metadata": {
    "language": "python",
    "name": "session_context"
   },
   "outputs": [],
   "source": [
    "# establish a session\n",
    "session = get_active_session()\n",
    "\n",
    "# print the current session context\n",
    "print(f\"\"\"\n",
    "SESSION CONTEXT\n",
    "  Account:   {session.get_current_account()}\n",
    "  Role:      {session.get_current_role()}\n",
    "  Database:  {session.get_current_database()}\n",
    "  Schema:    {session.get_current_schema()}\n",
    "  Warehouse: {session.get_current_warehouse()}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0f7cb-1f91-44c0-ae47-286df56a9c3d",
   "metadata": {
    "collapsed": false,
    "name": "TWEET_TABLES"
   },
   "source": [
    "## Create Tweet Tables\n",
    "\n",
    "We'll create two tables for storing fan tweets\n",
    "- `raw_tweets`: a landing table for raw, simulated tweets\n",
    "- `enriched_tweets`: a table for tweets which have been enriched with various Cortex AI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e5200-ff2d-4347-a613-54aa3eca4236",
   "metadata": {
    "language": "sql",
    "name": "create_raw_tweets_table"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE RAW_TWEETS (\n    TWEET_ID STRING,\n    TWEET_TEXT STRING,\n    USER_HANDLE STRING,\n    USER_LOCATION STRING,\n    RETWEET_COUNT INTEGER,\n    LIKE_COUNT INTEGER,\n    REPLY_COUNT INTEGER,\n    QUOTE_COUNT INTEGER,\n    FOLLOWER_COUNT INTEGER,\n    VERIFIED_STATUS BOOLEAN,\n    COMMENT_COUNT INTEGER,\n    GAME_MINUTE INTEGER,\n    CREATED_AT TIMESTAMP_NTZ\n);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbd1f9-e87f-43e8-a3c5-5c8bbe0f70b3",
   "metadata": {
    "language": "sql",
    "name": "create_enriched_tweets_table"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE ENRICHED_TWEETS (\n    tweet_id VARCHAR(255) PRIMARY KEY,\n    tweet_text VARCHAR(1000),\n    user_handle VARCHAR(50),\n    user_location VARCHAR(100),\n    retweet_count INTEGER,\n    like_count INTEGER,\n    reply_count INTEGER,\n    quote_count INTEGER,\n    follower_count INTEGER,\n    verified_status BOOLEAN,\n    comment_count INTEGER,\n    game_minute INTEGER,\n    created_at TIMESTAMP_NTZ,\n    sentiment_output FLOAT,\n    summary_output VARCHAR,\n    complete_response OBJECT,\n    processed_at TIMESTAMP_NTZ,\n    complete_output_array ARRAY,\n    complete_output_string VARCHAR\n)\n;"
  },
  {
   "cell_type": "markdown",
   "id": "a10362c2-6319-4b97-9e9c-c879b53ec7f8",
   "metadata": {
    "collapsed": false,
    "name": "RECREATE_TWEETS"
   },
   "source": [
    "## Generating Context-Specific Tweets with Cortex AI\n",
    "\n",
    "We'll use the [SNOWFLAKE.CORTEX.COMPLETE](https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex) to build contex-specific tweets, in this case tweets about an NBA game.\n",
    "\n",
    "_Why this matters_:\n",
    "- Gathering enough data to build enterprise-ready applications can be challenging\n",
    "- More and more companies have turned to AI to generate synthetic data to train other AI applications\n",
    "- Synthetic data is crucial for AI applications because it provides a cost-effective and privacy-preserving way to generate large, diverse datasets, overcoming limitations of scarce or sensitive real-world data\n",
    "\n",
    "With Snowflake, you can generate synthetic data using Cortex and also the native [GENERATE_SYNTHETIC_DATA](https://docs.snowflake.com/en/user-guide/synthetic-data) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94151c83-e7c1-454c-a5d3-3d180ebeb0a4",
   "metadata": {
    "language": "python",
    "name": "tweet_attributes"
   },
   "outputs": [],
   "source": [
    "EMOTIONS = [\n",
    "    \"excited\", \"upset\", \"nervous\", \"thrilled\", \"frustrated\", \"ecstatic\",\n",
    "    \"disappointed\", \"hyped\", \"stunned\", \"pumped\", \"heartbroken\", \"awed\",\n",
    "    \"anxious\", \"elated\", \"furious\", \"relieved\", \"nostalgic\", \"impressed\",\n",
    "    \"bored\", \"hopeful\", \"shocked\", \"overjoyed\", \"tense\", \"proud\",\n",
    "    \"exhausted\", \"confused\", \"amused\", \"enraged\", \"content\", \"skeptical\",\n",
    "    \"inspired\", \"devastated\", \"grateful\", \"anticipating\", \"smug\", \"awed\"\n",
    "]\n",
    "PLAYERS = [\n",
    "    \"Rookie Jaden Cole, crossover king\",\n",
    "    \"Captain Maya Reed, sharpshooting star\",\n",
    "    \"Center Amari Blake, rim protector\",\n",
    "    \"Point Guard Kai Nguyen, playmaking maestro\",\n",
    "    \"Forward Zoe Hunter, dunk machine\",\n",
    "    \"Sixth Man Riley Patel, clutch shooter\",\n",
    "    \"Veteran Lena Brooks, defensive anchor\",\n",
    "    \"Sharpshooter Alex Chen, three-point specialist\",\n",
    "    \"Defensive Stopper Taylor Green, lockdown artist\",\n",
    "    \"Bench Sparkplug Sam Rivera, energy booster\",\n",
    "    \"Veteran Playmaker Jordan Lee, court general\",\n",
    "    \"High-Flying Forward Casey Thompson, above-the-rim threat\",\n",
    "    \"Gritty Rebounder Morgan White, glass cleaner\",\n",
    "    \"Crafty Ballhandler Avery Kim, assist machine\",\n",
    "    \"Towering Center Drew Wilson, paint patroller\",\n",
    "    \"Speedy Guard Quinn Parker, transition terror\",\n",
    "    \"Stretch Four Jamie Ortiz, floor spacer\",\n",
    "    \"Hustle King Devon Miles, effort machine\",\n",
    "    \"Rookie Sensation Ellie Ford, fearless finisher\",\n",
    "    \"Fan Favorite Chris Lowe, trick-shot artist\",\n",
    "    \"Backup Big Tatum Hayes, post-up powerhouse\",\n",
    "    \"Perimeter Threat Skylar Dean, catch-and-shoot ace\",\n",
    "    \"Tenacious Wing Blair Evans, all-around grinder\",\n",
    "    \"Undersized Scrapper Nick Soto, heart and soul\",\n",
    "    \"Sophomore Standout Liam Gray, rising star\",\n",
    "    \"Silent Assassin Peyton Shaw, quiet killer\",\n",
    "    \"Veteran Enforcer Reese Carter, physical force\",\n",
    "    \"Dynamic Duo Leader Harper Lane, team glue\"\n",
    "]\n",
    "ACTIONS = [\n",
    "    \"nails a deep three-pointer\",\n",
    "    \"throws down a monster slam dunk\",\n",
    "    \"dishes a no-look pass\",\n",
    "    \"swats a shot into the stands\",\n",
    "    \"crosses over two defenders\",\n",
    "    \"hits a fadeaway jumper\",\n",
    "    \"steals the ball and sprints for a layup\",\n",
    "    \"banks in a buzzer-beater\",\n",
    "    \"executes a perfect pick-and-roll\",\n",
    "    \"threads a needle with a behind-the-back pass\",\n",
    "    \"posterizes a defender with a dunk\",\n",
    "    \"drains a contested fadeaway\",\n",
    "    \"locks down the opponent's star player\",\n",
    "    \"grabs a crucial offensive rebound\",\n",
    "    \"draws a charge with savvy positioning\",\n",
    "    \"hits a step-back jumper over tight defense\",\n",
    "    \"flips a one-handed pass to the corner\",\n",
    "    \"skies for a putback slam\",\n",
    "    \"fakes out a defender with a hesitation\",\n",
    "    \"snags a tipped pass for a fast break\",\n",
    "    \"buries a pull-up jumper in transition\",\n",
    "    \"denies a drive with a perfectly timed block\",\n",
    "    \"spins baseline for a reverse layup\",\n",
    "    \"sinks a floater over outstretched arms\",\n",
    "    \"whips a cross-court pass for an open three\",\n",
    "    \"elevates for a tomahawk dunk\",\n",
    "    \"shuts down a pick with quick feet\",\n",
    "    \"splashes a midrange shot off the dribble\",\n",
    "    \"secures a loose ball in traffic\",\n",
    "    \"finishes a tough and-one at the rim\",\n",
    "    \"strips the ball on a double-team\",\n",
    "    \"rises for a game-sealing block\"\n",
    "]\n",
    "VENDORS = [\n",
    "    \"Burger Bonanza, with sizzling burgers\",\n",
    "    \"Pizza Pavilion, wood-fired garlic knots\",\n",
    "    \"Nacho Nation, spicy loaded nachos\",\n",
    "    \"Sweet Spot, cinnamon funnel cakes\",\n",
    "    \"Popcorn Palace, buttery buckets\",\n",
    "    \"Slam Dunk Dogs, gourmet hot dogs\",\n",
    "    \"Hoop Gear Hub, team jerseys and caps\"\n",
    "]\n",
    "SECTIONS = [\n",
    "    \"West Concourse, rocking live music\",\n",
    "    \"East Plaza, buzzing with fan games\",\n",
    "    \"Sky Deck, premium rooftop views\",\n",
    "    \"South Bleachers, rowdy chant leaders\",\n",
    "    \"North Stands, family-friendly fun\",\n",
    "    \"Courtside VIP, star-studded seats\",\n",
    "    \"Fan Zone, interactive dunk contests\"\n",
    "]\n",
    "GAME_MOMENTS = [\n",
    "    \"a game-tying three at the buzzer\",\n",
    "    \"a ferocious alley-oop dunk\",\n",
    "    \"a controversial foul call\",\n",
    "    \"a clutch steal in crunch time\",\n",
    "    \"a dramatic overtime winner\",\n",
    "    \"a comeback from 15 points down\",\n",
    "    \"a no-look assist for an easy layup\",\n",
    "    \"a block that shakes the arena\",\n",
    "    \"a full-court press that forces a turnover\",\n",
    "    \"a fast-break dunk that ignites the crowd\",\n",
    "    \"a technical foul for arguing with the ref\",\n",
    "    \"a record-breaking scoring streak\",\n",
    "    \"a momentum-shifting block\",\n",
    "    \"a half-court shot that swishes through\",\n",
    "    \"a flagrant foul that sparks controversy\",\n",
    "    \"a timeout called to ice the free-throw shooter\",\n",
    "    \"a buzzer-beating tip-in to win\",\n",
    "    \"a double-overtime nail-biter\",\n",
    "    \"a rookie’s breakout scoring run\",\n",
    "    \"a defensive stand that holds the lead\",\n",
    "    \"a three-pointer that breaks the franchise record\",\n",
    "    \"a steal followed by a behind-the-back dunk\",\n",
    "    \"a missed call that has the crowd roaring\",\n",
    "    \"a perfect inbounds play for the win\",\n",
    "    \"a shot clock violation that shifts momentum\",\n",
    "    \"a player ejection after a heated exchange\",\n",
    "    \"a fan-favorite hits a milestone\",\n",
    "    \"a last-second block to secure the victory\",\n",
    "    \"a crossover that sends the defender sliding\",\n",
    "    \"a putback dunk off a missed free throw\",\n",
    "    \"a referee review that overturns a call\",\n",
    "    \"a celebration dunk that draws a penalty\"\n",
    "]\n",
    "REASONS = [\n",
    "    \"reacting to an insane play\",\n",
    "    \"raving about the food\",\n",
    "    \"complaining about long lines\",\n",
    "    \"soaking in the electric vibe\",\n",
    "    \"cheering a clutch moment\",\n",
    "    \"marveling at the halftime show\",\n",
    "    \"hyping the crowd’s energy\",\n",
    "    \"gushing over a player’s hustle\",\n",
    "    \"celebrating a personal best\",\n",
    "    \"critiquing the coach's strategy\",\n",
    "    \"admiring the team's chemistry\",\n",
    "    \"lamenting a missed opportunity\",\n",
    "    \"praising the arena's acoustics\",\n",
    "    \"commenting on the officiating\",\n",
    "    \"sharing a funny moment from the stands\",\n",
    "    \"expressing disbelief at a stat line\",\n",
    "    \"bragging about courtside seats\",\n",
    "    \"mocking the rival team’s fans\",\n",
    "    \"noticing a celebrity in the crowd\",\n",
    "    \"loving the pregame light show\",\n",
    "    \"groaning at the parking chaos\",\n",
    "    \"cheering a teammate’s assist\",\n",
    "    \"shouting about a bad call\",\n",
    "    \"toasting to a big lead\",\n",
    "    \"capturing the jumbotron dance cam\",\n",
    "    \"boasting about the team’s defense\",\n",
    "    \"reminiscing about past games\",\n",
    "    \"geeking out over player stats\",\n",
    "    \"thanking the mascot for the laughs\",\n",
    "    \"envying the VIP lounge perks\",\n",
    "    \"ranting about the shot clock reset\",\n",
    "    \"singing along to the arena anthem\"\n",
    "]\n",
    "BUSINESS_REASONS = [\n",
    "    \"raving about the food\",\n",
    "    \"complaining about long lines\",\n",
    "    \"bragging about courtside seats\",\n",
    "    \"envying the VIP lounge perks\",\n",
    "    \"groaning at the parking chaos\",\n",
    "    \"marveling at the halftime show\",\n",
    "    \"loving the pregame light show\",\n",
    "    \"capturing the jumbotron dance cam\",\n",
    "    \"thanking the mascot for the laughs\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d1871-3f93-4f5d-b43d-d389ccf659b4",
   "metadata": {
    "language": "python",
    "name": "simulate_tweet"
   },
   "outputs": [],
   "source": [
    "def rewrite_text(\n",
    "    text:str,\n",
    "    emotions:list[str]=EMOTIONS,\n",
    "    players:list[str]=PLAYERS,\n",
    "    actions:list[str]=ACTIONS,\n",
    "    vendors:list[str]=VENDORS,\n",
    "    sections:list[str]=SECTIONS,\n",
    "    game_moments:list[str]=GAME_MOMENTS,\n",
    "    business_reasons:list[str]=BUSINESS_REASONS,\n",
    "    reasons:list[str]=REASONS,\n",
    "    is_comment:bool=False, \n",
    "    game_minute:int=random.randint(0, 65)\n",
    ") -> str:\n",
    "\n",
    "    context = \"comment\" if is_comment else \"tweet\"\n",
    "    escaped_text = text.replace('\"', '\\\\\"')\n",
    "\n",
    "    time_periods = [\n",
    "        \"early in the first quarter\" if game_minute <= 12 else\n",
    "        \"late in the first quarter\" if game_minute <= 24 else\n",
    "        \"second quarter\" if game_minute <= 36 else\n",
    "        \"third quarter\" if game_minute <= 48 else\n",
    "        \"fourth quarter\" if game_minute <= 60 else\n",
    "        \"overtime\" if game_minute <= 65 else\n",
    "        \"final moments\"\n",
    "    ]\n",
    "\n",
    "    # make random selections from predefined lists\n",
    "    selected_emotion = random.choice(emotions)\n",
    "    selected_player = random.choice(players)\n",
    "    selected_action = random.choice(actions)\n",
    "    selected_vendor = random.choice(vendors)\n",
    "    selected_section = random.choice(sections)\n",
    "    selected_moment = random.choice(game_moments)\n",
    "    \n",
    "    business_focus = random.random() < 0.7\n",
    "    if business_focus:\n",
    "        selected_reason = random.choice(business_reasons)\n",
    "        focus_instruction = \"Particularly focus on aspects that could help the business make decisions to drive revenue, such as customer satisfaction with vendors, lines, or stadium amenities.\"\n",
    "    else:\n",
    "        selected_reason = random.choice(reasons)\n",
    "        focus_instruction = \"\"\n",
    "    \n",
    "    selected_time = time_periods[0]\n",
    "\n",
    "    # create a prompt to generate a simulated tweet\n",
    "    prompt_content = f\"\"\"\n",
    "    Rewrite this {context} to fit a basketball game day at ArenaFlow stadium, creating a vivid and engaging tweet that captures the unique atmosphere. {focus_instruction}\n",
    "    Focus on a combination of the following elements, choosing at least two to highlight:\n",
    "    - **Player and action**: Feature {selected_player} who {selected_action}.\n",
    "    - **Vendor and offering**: Include {selected_vendor}.\n",
    "    - **Stadium section**: Reference {selected_section}.\n",
    "    - **Fan reaction**: Capture a {selected_emotion} fan {selected_reason}.\n",
    "    - **Game moment**: Highlight {selected_moment} {selected_time}.\n",
    "    \n",
    "    To ensure variety and freshness:\n",
    "    - Use diverse vocabulary and sentence structures, e.g., 'the arena erupts like a volcano' instead of 'the crowd goes wild.'\n",
    "    - Incorporate sensory details, like the squeak of sneakers or the aroma of popcorn.\n",
    "    - Vary the tone: excited, humorous, poetic, or analytical.\n",
    "    - Keep the tweet under 280 characters, including spaces and punctuation.\n",
    "    \n",
    "    Do not quote or mimic the original text. Original {context}: \"{escaped_text}\".\n",
    "    Return the rewritten text as a plain string.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "          SNOWFLAKE.CORTEX.COMPLETE(\n",
    "            'mistral-large2',\n",
    "            [\n",
    "              {{\n",
    "                'role': 'user',\n",
    "                'content': '{prompt_content.replace(\"'\", \"''\")}'\n",
    "              }}\n",
    "            ],\n",
    "            {{\n",
    "              'temperature': 0.7,\n",
    "              'max_tokens': 500\n",
    "            }}\n",
    "          ) AS rewritten_text\n",
    "        \"\"\"\n",
    "        \n",
    "        result = session.sql(query).collect()\n",
    "        \n",
    "        if not result:\n",
    "            raise Exception(f\"No response from SNOWFLAKE.CORTEX.COMPLETE for {context}\")\n",
    "        \n",
    "        response = result[0][\"REWRITTEN_TEXT\"]\n",
    "        try:\n",
    "            response_dict = json.loads(response)\n",
    "            if \"choices\" in response_dict and response_dict[\"choices\"]:\n",
    "                rewritten_text = response_dict[\"choices\"][0][\"messages\"]\n",
    "                if rewritten_text.startswith('\"') and rewritten_text.endswith('\"'):\n",
    "                    rewritten_text = rewritten_text[1:-1]\n",
    "            else:\n",
    "                raise Exception(f\"Unexpected JSON response format: {response}\")\n",
    "        except json.JSONDecodeError:\n",
    "            rewritten_text = response\n",
    "        \n",
    "        return rewritten_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Cortex Complete failed for {context}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80919e22-b23d-40d1-bcd1-3055fb5a3fb3",
   "metadata": {
    "collapsed": false,
    "name": "SINGLE_TWEET"
   },
   "source": [
    "## Simulating a single tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b5d45-d7ef-4062-b87c-e9cfd43dc6d1",
   "metadata": {
    "language": "python",
    "name": "generate_single_raw_tweet"
   },
   "outputs": [],
   "source": "generator = Xprofile()\nusers, tweets, comments, likes, retweets = generator.generate_fake_twitter_data(user_count=1, tweets_per_user=1)\nprint('USERS')\npprint(users[0], indent=4)\nprint('TWEETSW')\npprint(tweets[0], indent=4)\nprint('COMMENTS')\npprint(comments[0], indent=4)\nprint('LIKES')\npprint(likes[0], indent=4)\nprint('RETWEETS')\npprint(retweets[0], indent=4)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4b830-9b2b-474d-92f9-5a95d6304fcf",
   "metadata": {
    "language": "python",
    "name": "simulate_single_tweet"
   },
   "outputs": [],
   "source": [
    "test_tweet = tweets[0][\"text\"]\n",
    "augmented_tweet = rewrite_text(test_tweet, game_minute = 10)\n",
    "\n",
    "print(f\"\"\"\n",
    "RAW TWEET:\n",
    "{test_tweet}\n",
    " \n",
    "SIMULATED TWEET:\n",
    "{augmented_tweet}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b13ba-c4f4-4a8b-95dc-d0cb7f114325",
   "metadata": {
    "collapsed": false,
    "name": "MULTIPLE_TWEETS"
   },
   "source": [
    "## Simulating multiple tweets\n",
    "\n",
    "Now that simulating a single tweet looks good, we'll build out a framework for simulating multiple tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4a763-b44d-449d-a594-3f239020af94",
   "metadata": {
    "language": "python",
    "name": "def_process_tweet"
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet:dict, users:dict, game_minute:int) -> Union[None, dict]:\n",
    "    \n",
    "    print(f\"Processing tweet: {tweet['tweet_id']}\")\n",
    "    \n",
    "    try:\n",
    "        tweet_rewritten = rewrite_text(tweet['text'], is_comment=False, game_minute=game_minute)\n",
    "        \n",
    "        print(f\"Rewritten tweet: {tweet_rewritten}\")\n",
    "        \n",
    "        user = next((u for u in users if u[\"user_id\"] == tweet[\"user_id\"]), None)\n",
    "        if not user:\n",
    "            return None\n",
    "\n",
    "        # Simplify scaling with single factor, no caps\n",
    "        scale_factor = random.uniform(0.5, 1.5)  # 50%–150% of original\n",
    "        retweet_count = max(0, int(tweet[\"retweet_count\"] * scale_factor))\n",
    "        like_count = max(0, int(tweet[\"like_count\"] * scale_factor))\n",
    "        reply_count = max(0, int(tweet[\"reply_count\"] * scale_factor))\n",
    "        quote_count = max(0, int(tweet[\"quote_count\"] * scale_factor))\n",
    "        follower_count = max(0, int(user[\"follower_count\"] * scale_factor))\n",
    "\n",
    "        tweet_data = {\n",
    "            \"TWEET_ID\": f\"TWEET_{tweet['tweet_id']}\",\n",
    "            \"TWEET_TEXT\": tweet_rewritten,\n",
    "            \"USER_HANDLE\": f\"@{user['username']}\",\n",
    "            \"USER_LOCATION\": user[\"location\"],\n",
    "            \"RETWEET_COUNT\": retweet_count,\n",
    "            \"LIKE_COUNT\": like_count,\n",
    "            \"REPLY_COUNT\": reply_count,\n",
    "            \"QUOTE_COUNT\": quote_count,\n",
    "            \"FOLLOWER_COUNT\": follower_count,\n",
    "            \"VERIFIED_STATUS\": user[\"verified_status\"],\n",
    "            \"COMMENT_COUNT\": 0,\n",
    "            \"GAME_MINUTE\": game_minute,\n",
    "            \"CREATED_AT\": datetime.now().replace(tzinfo=None)  # Convert to TIMESTAMP_NTZ\n",
    "        }\n",
    "        \n",
    "        return tweet_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tweet {tweet['tweet_id']}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb0075-1565-4a86-b7f9-044c9d196132",
   "metadata": {
    "language": "python",
    "name": "process_multiple_tweet"
   },
   "outputs": [],
   "source": "num_tweets = 5\ngenerator = Xprofile()\nusers, tweets, comments, likes, retweets = generator.generate_fake_twitter_data(user_count=num_tweets, tweets_per_user=1)\n\n# Process only the first n tweets\nraw_tweets = tweets[:num_tweets]\nprocessed_tweets = []\n\n\n# iterate through raw tweets, processing each with Cortex Complete\nfor tweet in raw_tweets:\n\n    # simulate tweet with Cortex Complete\n    processed_tweet = process_tweet(tweet, users, game_minute = random.randint(0, 65))\n\n    # append to list of processed tweets\n    processed_tweets.append(processed_tweet)\n\n\n# Use Snowpark DataFrame to save simulated tweets to the RAW_TWEETS table\nif processed_tweets:\n    df_batch = session.create_dataframe(processed_tweets)\n    df_batch.write.mode(\"append\").save_as_table(\"RAW_TWEETS\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ec8cb-4bf9-4c9d-9337-f09aceae29ed",
   "metadata": {
    "language": "sql",
    "name": "verify_results"
   },
   "outputs": [],
   "source": "SELECT * \nFROM RAW_TWEETS \nORDER BY tweet_id;"
  },
  {
   "cell_type": "markdown",
   "id": "5ef421af-4d35-4c16-a1a6-3e296129bf67",
   "metadata": {
    "collapsed": false,
    "name": "ENRICH_TWEETS"
   },
   "source": [
    "## Unlocking Insights with Cortex AI-Powered Analysis\n",
    "\n",
    "All Cortex functions can be called natively in SQL, allowing you to:\n",
    "- Easily integrate LLM batch processing directly into your data engineering pipelines\n",
    "- Execute Cortex AI functions entire tables of data all at once\n",
    "- Apply existing [data governance](https://docs.snowflake.com/en/guides-overview-govern) policies to  Cortex AI (RBAC, tagging, masking, row-level security, etc.)\n",
    "\n",
    "\n",
    "We'll use several Cortex functions to begin batch processing our tweets:\n",
    "- [SNOWFLAKE.CORTEX.SENTIMENT](https://docs.snowflake.com/en/sql-reference/functions/sentiment-snowflake-cortex): Returns an overall sentiment score for the given input text\n",
    "- [SNOWFLAKE.CORTEX.SUMMARIZE](https://docs.snowflake.com/en/sql-reference/functions/summarize-snowflake-cortex): Summarizes the given input text\n",
    "- [SNOWFLAKE.CORTEX.COMPLETE](https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex): Given a prompt, generates a response (completion) using your choice of supported language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633e20e-4583-409f-ae83-a2f203ccd8c0",
   "metadata": {
    "language": "sql",
    "name": "summarize_test"
   },
   "outputs": [],
   "source": "SET summarize_prompt = 'Summarize the following tweet in 1-2 sentences, focusing on fan engagement, player highlights, or vendor experiences, and highlight specific business opportunities like improving operations, targeting promotions, or addressing customer pain points: ';\n\nSELECT\n    tweet_text as raw_tweet\n    ,SNOWFLAKE.CORTEX.SUMMARIZE($summarize_prompt || tweet_text)::varchar AS summarized_tweet\nFROM\n    RAW_TWEETS\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771f413-ba31-4a20-a1e5-9cd2ef251382",
   "metadata": {
    "language": "sql",
    "name": "sentiment_test"
   },
   "outputs": [],
   "source": "SELECT\n    TWEET_TEXT as RAW_TWEET,\n    SNOWFLAKE.CORTEX.SENTIMENT(TWEET_TEXT) AS TWEET_SENTIMENT\nFROM\n    RAW_TWEETS\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4026010-67f7-4bcb-b0b0-50ce0e392474",
   "metadata": {
    "language": "sql",
    "name": "complete_variables"
   },
   "outputs": [],
   "source": [
    "SET llm = 'mistral-large2';\n",
    "SET instructions = 'Analyze the tweet and categorize it into one or more of the below categories based on its content: ';\n",
    "SET output_format = 'Return an array of category names that best fit the tweet: ';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145ff52-4ba9-4fc1-89fd-6728610d7d27",
   "metadata": {
    "language": "sql",
    "name": "complete_test"
   },
   "outputs": [],
   "source": "SELECT\n    TWEET_TEXT as RAW_TWEET,\n    SNOWFLAKE.CORTEX.COMPLETE(\n        $llm,\n        [{\n            'role': 'user',\n            'content': $instructions || \n                       '1. Fan Engagement (fan enthusiasm, chants, crowd energy), ' ||\n                       '2. Player Highlight (praising player performance), ' ||\n                       '3. Vendor Opportunity (positive or negative food/merchandise experiences, excluding crowded lines or maintenance), ' ||\n                       '4. Game Atmosphere (overall arena vibe), ' ||\n                       '5. Vendor Operations (crowded vendor lines with keywords like \"long line\", \"wait time\", \"queue\", \"crowded\", \"slow\", \"register\", or maintenance issues like \"spill\", \"mess\", \"broken\", \"dirty\", \"clean\"). ' ||\n                       $output_format || tweet_text\n                    }],\n                {'temperature': 0, 'max_tokens': 100}\n            ) AS complete_response\nFROM\n    RAW_TWEETS\n;"
  },
  {
   "cell_type": "markdown",
   "id": "372c47a8-b3e8-4def-8c5d-b541da918bb8",
   "metadata": {
    "collapsed": false,
    "name": "STRUCTURED_OUTPUT"
   },
   "source": [
    "## Cortex Complete Structured Outputs\n",
    "\n",
    "[Structured output](https://docs.snowflake.com/en/user-guide/snowflake-cortex/complete-structured-outputs) lets you supply a JSON schema that completion responses must follow.\n",
    "\n",
    "**_Why this matters_**:\n",
    "Output from even the most sophisticated LLMs can sometimes be inconsistent. By applying a structured schema, Cortes will ensure that the model's output will conform to the supplied schema\n",
    "\n",
    "```sql\n",
    "options: {\n",
    "    ...\n",
    "    response_format: {\n",
    "        'type': 'json',\n",
    "        'schema': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'property_name': {\n",
    "                    'type': 'string'\n",
    "                },\n",
    "                ...\n",
    "            },\n",
    "            'required': ['property_name', ...]\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65aeb2d-e5b7-446b-a189-5f37439d13ff",
   "metadata": {
    "language": "sql",
    "name": "complete_test_with_structured_output"
   },
   "outputs": [],
   "source": "SELECT\n    TWEET_TEXT as RAW_TWEET,\n    SNOWFLAKE.CORTEX.COMPLETE(\n        $llm\n        ,[{\n            'role': 'user',\n            'content': $instructions || \n                       '1. Fan Engagement (fan enthusiasm, chants, crowd energy), ' ||\n                       '2. Player Highlight (praising player performance), ' ||\n                       '3. Vendor Opportunity (positive or negative food/merchandise experiences, excluding crowded lines or maintenance), ' ||\n                       '4. Game Atmosphere (overall arena vibe), ' ||\n                       '5. Vendor Operations (crowded vendor lines with keywords like \"long line\", \"wait time\", \"queue\", \"crowded\", \"slow\", \"register\", or maintenance issues like \"spill\", \"mess\", \"broken\", \"dirty\", \"clean\"). ' ||\n                       $output_format || tweet_text\n        }]\n        ,{\n            'temperature': 0,\n            'max_tokens': 100,\n            'response_format': {\n                    'type': 'json',\n                    'schema': {\n                        'type': 'object',\n                        'properties': {\n                            'categories': {\n                                'type': 'array',\n                                'items': { 'type': 'string' }\n                            }\n                        },\n                        'required': ['categories']\n                    }\n                }\n            }\n        ) AS complete_response\nFROM\n    RAW_TWEETS\n;"
  },
  {
   "cell_type": "markdown",
   "id": "cca0cd4d-246f-4edc-89ba-46b47aae5c1e",
   "metadata": {
    "collapsed": false,
    "name": "FULL_LLM_PROCESSING"
   },
   "source": [
    "## Full LLM Processing\n",
    "\n",
    "The below query combines all Cortex function calls into a single query\n",
    "- Tweet summarization\n",
    "- Tweet sentiment\n",
    "- Tweet categorization with structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecd995-f0ff-4ced-9d35-bd6af50306a3",
   "metadata": {
    "language": "sql",
    "name": "llm_processing"
   },
   "outputs": [],
   "source": "SELECT\n    *\n    ,SNOWFLAKE.CORTEX.SUMMARIZE($summarize_prompt || tweet_text) AS summary_output\n    ,SNOWFLAKE.CORTEX.SENTIMENT(tweet_text) AS sentiment_output\n    ,SNOWFLAKE.CORTEX.COMPLETE(\n        $llm,\n        [{\n            'role': 'user',\n            'content': $instructions || \n                       '1. Fan Engagement (fan enthusiasm, chants, crowd energy), ' ||\n                       '2. Player Highlight (praising player performance), ' ||\n                       '3. Vendor Opportunity (positive or negative food/merchandise experiences, excluding crowded lines or maintenance), ' ||\n                       '4. Game Atmosphere (overall arena vibe), ' ||\n                       '5. Vendor Operations (crowded vendor lines with keywords like \"long line\", \"wait time\", \"queue\", \"crowded\", \"slow\", \"register\", or maintenance issues like \"spill\", \"mess\", \"broken\", \"dirty\", \"clean\"). ' ||\n                       $output_format || tweet_text\n        }],\n        {\n            'temperature': 0,\n            'max_tokens': 100,\n            'response_format': {\n                    'type': 'json',\n                    'schema': {\n                        'type': 'object',\n                        'properties': {\n                            'categories': {\n                                'type': 'array',\n                                'items': { 'type': 'string' }\n                            }\n                        },\n                        'required': ['categories']\n                    }\n                }\n            }\n        ) AS complete_response\nFROM\n    RAW_TWEETS\n;"
  },
  {
   "cell_type": "markdown",
   "id": "133b7e15-ef7a-40fa-a1ad-c3921adc66df",
   "metadata": {
    "collapsed": false,
    "name": "FULL_TWEET_PROCESSING"
   },
   "source": [
    "## Full Tweet Processing\n",
    "\n",
    "The below CTE calls all of our Cortex processing functions in a single statement and additionally generates an array of categories from the COMPLETE structured out\n",
    "\n",
    "This CTE takes advantage of [cell referencing](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-develop-run#reference-cells-and-variables-in-sf-notebooks). Rather than rewriting the LLM processing query, we can simply write `select * from {{llm_processing}}` to use the results from the previous `{{llm_processing}}` cell output\n",
    "\n",
    "-> _This is particularly useful when writing complex CTE's!!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43120edf-6fa9-4fd9-8f26-e1ef169432e4",
   "metadata": {
    "language": "sql",
    "name": "fully_processed_results"
   },
   "outputs": [],
   "source": [
    "WITH\n",
    "categorization AS (\n",
    "    select * from {{llm_processing}}\n",
    ")\n",
    "SELECT \n",
    "    c.*\n",
    "    ,ARRAY_AGG(cat.value)::ARRAY AS complete_output_array\n",
    "    ,ARRAY_TO_STRING(complete_output_array, ',') AS complete_output_string\n",
    "FROM\n",
    "    categorization c\n",
    "LEFT JOIN LATERAL FLATTEN(input => c.complete_response:structured_output) so\n",
    "LEFT JOIN LATERAL FLATTEN(input => so.value:raw_message:categories) cat\n",
    "GROUP BY ALL\n",
    "HAVING\n",
    "    complete_output_string IS NOT NULL\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb64839-a336-45f1-9e51-df09356bb38e",
   "metadata": {
    "collapsed": false,
    "name": "CONTINUOUS_BATCH_PROCESSING"
   },
   "source": [
    "## Building Continuous Data Engineering Pipelines with Cortex AI\n",
    "\n",
    "Now that we've built a query to batch process our unstructured data with Cortex, we can leverage other Snowflake data engineering features to continuously process new tweets as they flow into our environment\n",
    "\n",
    "1. Simulate streaming tweets into the `RAW_TWEETS` table\n",
    "2. Create stored procedure for LLM batch processing\n",
    "3. Create a stream on the `RAW_TWEETS` to capture DML updates\n",
    "4. Build a [triggered task](https://docs.snowflake.com/en/user-guide/tasks-intro#triggered-tasks) to call our SPROC whenever our stream has data\n",
    "5. Insert processed tweets into the `ENRICHED_TWEETS` table\n",
    "6. Build a [Dynamic Table](https://docs.snowflake.com/en/user-guide/dynamic-tables-intro) to generate our \"gold layer\" data for BI, reporting, and other analysis\n",
    "7. Develop a chat app with [Cortex Analyst](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst) and [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit) for a \"talk to your data\" experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d94f4-7909-412c-9c9b-3d1e87eb55c5",
   "metadata": {
    "language": "sql",
    "name": "sproc_definition"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE PROCESS_NEW_TWEETS()\nRETURNS STRING\nLANGUAGE SQL\nEXECUTE AS CALLER\nAS\n$$\nBEGIN\n\n    -- Insert new records from raw_tweets into enriched_tweets with sentiment, summary, and categorization\n    INSERT INTO ENRICHED_TWEETS (\n        tweet_id,\n        tweet_text,\n        user_handle,\n        user_location,\n        retweet_count,\n        like_count,\n        reply_count,\n        quote_count,\n        follower_count,\n        verified_status,\n        comment_count,\n        game_minute,\n        created_at,\n        sentiment_output,\n        summary_output,\n        complete_response,\n        processed_at,\n        complete_output_array,\n        complete_output_string\n    )\n    WITH \n    tweets AS (\n        SELECT \n            *\n        FROM\n            RAW_TWEETS\n        WHERE 1=1\n            AND tweet_id IS NOT NULL\n    ),\n    categorization AS (\n        SELECT \n            t.*\n            ,SNOWFLAKE.CORTEX.SENTIMENT(t.tweet_text) AS sentiment_output\n            ,SNOWFLAKE.CORTEX.SUMMARIZE(\n                'Summarize the following tweet in 1-2 sentences, focusing on fan engagement, player highlights, or vendor experiences, and highlight specific business opportunities like improving operations, targeting promotions, or addressing customer pain points: ' || t.tweet_text\n            ) AS summary_output\n            ,SNOWFLAKE.CORTEX.COMPLETE(\n                'mistral-large2',\n                [{\n                    'role': 'user',\n                    'content': 'Analyze the tweet and categorize it into one or more of these five categories based on its content: ' ||\n                               '1. Fan Engagement (fan enthusiasm, chants, crowd energy), ' ||\n                               '2. Player Highlight (praising player performance), ' ||\n                               '3. Vendor Opportunity (positive or negative food/merchandise experiences, excluding crowded lines or maintenance), ' ||\n                               '4. Game Atmosphere (overall arena vibe), ' ||\n                               '5. Vendor Operations (crowded vendor lines with keywords like \"long line\", \"wait time\", \"queue\", \"crowded\", \"slow\", \"register\", or maintenance issues like \"spill\", \"mess\", \"broken\", \"dirty\", \"clean\"). ' ||\n                               'Return an array of category names that best fit the tweet: ' || t.tweet_text\n                }]\n                ,{\n                    'temperature': 0\n                    ,'max_tokens': 100\n                    ,'response_format': {\n                        'type': 'json',\n                        'schema': {\n                            'type': 'object',\n                            'properties': {\n                                'categories': {\n                                    'type': 'array',\n                                    'items': { 'type': 'string' }\n                                }\n                            },\n                            'required': ['categories']\n                        }\n                    }\n                }\n            ) AS complete_response\n        FROM tweets as t\n    )\n    SELECT \n        c.*\n        ,CURRENT_TIMESTAMP(2) as processed_at\n        ,ARRAY_AGG(cat.value)::ARRAY AS complete_output_array\n        ,ARRAY_TO_STRING(complete_output_array, ',') AS complete_output_string\n    FROM categorization c\n    LEFT JOIN LATERAL FLATTEN(input => c.complete_response:structured_output) so\n    LEFT JOIN LATERAL FLATTEN(input => so.value:raw_message:categories) cat\n    GROUP BY ALL\n    HAVING\n        complete_output_string IS NOT NULL\n    ;\n    \n    RETURN 'Successfully processed new tweets into enriched_tweets';\nEXCEPTION\n    WHEN OTHER THEN\n        RETURN 'Error processing tweets: ' || SQLERRM;\nEND;\n$$;\n"
  },
  {
   "cell_type": "markdown",
   "id": "b2832588-a46e-4658-8e17-dc4ebe15bea6",
   "metadata": {
    "collapsed": false,
    "name": "STREAMS_AND_TASKS"
   },
   "source": [
    "## Triggered Tasks\n",
    "\n",
    "First we'll build a stream on `RAW_TWEETS` to record DML statements (updates, inserts, deletes) made against the table\n",
    "\n",
    "The task will call the `process_new_tweets()` SPROC whenever condition `SYSTEM$STREAM_HAS_DATA('raw_tweets_st')` evaluates to `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6b9dd-bd16-4bb6-9064-a5c53d27b484",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_triggered_task"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STREAM RAW_TWEETS_ST ON TABLE RAW_TWEETS;\n\nCREATE OR REPLACE TASK TWEET_PROCESSING\n  WAREHOUSE = DEV_WH_ARENAFLOW_HOLS\n  WHEN SYSTEM$STREAM_HAS_DATA('RAW_TWEETS_ST')\n  AS\n  CALL PROCESS_NEW_TWEETS();"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420605b-fc67-4f0e-ac60-d18afb335396",
   "metadata": {
    "language": "sql",
    "name": "suspend_resume_triggered_task"
   },
   "outputs": [],
   "source": "ALTER TASK tweet_processing RESUME;"
  },
  {
   "cell_type": "markdown",
   "id": "d6901fb3-303d-4a97-9fab-7c59a70b8880",
   "metadata": {
    "collapsed": false,
    "name": "STREAM_SETUP"
   },
   "source": [
    "## Continuous Batch Processing with Cortex\n",
    "\n",
    "The following functions simulates batches of tweets\n",
    "\n",
    "- A batch of tweets is generated from the `fake_profile` library\n",
    "- NBA specific tweets are generated using Cortex Complete\n",
    "- The batch of augmented tweets are converted to a [Snowpark DataFrame](https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes) then saved to the `RAW_TWEETS` table\n",
    "- The `process_new_tweets()` SPROC is called via the `tweet_processing` triggered task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4828f2-daae-4fc7-94c4-5f740830ba4b",
   "metadata": {
    "language": "python",
    "name": "def_insert_batch"
   },
   "outputs": [],
   "source": "async def insert_batch(batch_data, session):\n    if batch_data:\n        try:\n            df_batch = session.create_dataframe(batch_data)\n            df_batch.write.mode(\"append\").save_as_table(\"RAW_TWEETS\")\n            print(f\"Inserted batch of {len(batch_data)} tweets\")\n        except Exception as e:\n            print(f\"Error inserting batch: {str(e)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fe7b3-d2da-415b-ab04-ffc46c0b1925",
   "metadata": {
    "language": "python",
    "name": "def_simulate_streaming"
   },
   "outputs": [],
   "source": [
    "async def simulate_streaming(tweets, users, session, num_tweets=5):\n",
    "    \n",
    "    executor = ThreadPoolExecutor(max_workers=5)  # Limit concurrent workers\n",
    "    batch_size_range = (3, 15)  # Random batch size between 1 and 7\n",
    "    delay_range = (0.5, 2.0)  # Random delay between 0.5 and 2 seconds\n",
    "    cumulative_delay = 0.0  # Initialize cumulative delay to track simulated time\n",
    "\n",
    "    remaining_tweets = tweets[:num_tweets]\n",
    "    \n",
    "    while remaining_tweets:\n",
    "        \n",
    "        # Calculate current game minute based on cumulative delay (1 minute = 10 seconds of simulated time)\n",
    "        current_game_minute = min(int(cumulative_delay // 10), 65)\n",
    "        \n",
    "        batch_size = random.randint(*batch_size_range)\n",
    "        batch_tweets = remaining_tweets[:batch_size]\n",
    "        remaining_tweets = remaining_tweets[batch_size:]\n",
    "\n",
    "        # Process tweets in parallel with the current game minute\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = [loop.run_in_executor(executor, process_tweet, t, users, current_game_minute) for t in batch_tweets]\n",
    "        batch_data = await asyncio.gather(*tasks)\n",
    "        batch_data = [data for data in batch_data if data is not None]\n",
    "\n",
    "        # Insert batch asynchronously\n",
    "        if batch_data:\n",
    "            await insert_batch(batch_data, session)\n",
    "\n",
    "        # Simulate time passing with a random delay and update cumulative delay\n",
    "        delay = random.uniform(*delay_range)\n",
    "        cumulative_delay += delay\n",
    "        await asyncio.sleep(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2b497-9c08-4e11-a7e6-1607a0ce5228",
   "metadata": {
    "collapsed": false,
    "name": "DYNAMIC_TABLE"
   },
   "source": [
    "## Dynamic Table for Gold Layer Processing\n",
    "\n",
    "The `ENRICHED_TWEETS_DT` Dynamic Table is the final layer of processing in our data pipelines\n",
    "\n",
    "The DT will incrementally process new tweets as they are inserted into the `ENRICHED_TWEETS` table. The setting `TARGET_LAG = '1 minute'` ensures that our gold layer data is never more than 1 minute out of date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216378c-2174-418b-964f-4c2bcec54856",
   "metadata": {
    "language": "sql",
    "name": "create_dynamic_table"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE DYNAMIC TABLE ENRICHED_TWEETS_DT (\n    TWEET_ID,\n    RETWEETS,\n    LIKES,\n    REPLIES,\n    QUOTES,\n    CREATED_AT,\n    PROCESSED_AT,\n    STREAM_LATENCY,\n    GAME_MINUTE,\n    SENTIMENT,\n    SUMMARY,\n    TOPIC  \n)\nCLUSTER BY (GAME_MINUTE, SENTIMENT)\nREFRESH_MODE = AUTO\nWAREHOUSE = 'DEV_WH_ARENAFLOW_HOLS' \nTARGET_LAG = '1 minute'\nAS\nSELECT\n    tweet_id,\n    retweet_count,\n    like_count,\n    reply_count,\n    quote_count,\n    created_at,\n    processed_at,\n    TIMESTAMPDIFF(second, created_at, processed_at) AS stream_latency,\n    game_minute,\n    CASE\n        WHEN sentiment_output >= 0.7 THEN 'good'\n        ELSE 'bad'\n    END AS sentiment,\n    summary_output,\n    complete_output_string\nFROM\n   ENRICHED_TWEETS\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f2bbc-eec1-4348-abe7-013a5e718c9f",
   "metadata": {
    "language": "python",
    "name": "simulate_streaming"
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "generator = Xprofile()\n",
    "users, tweets, comments, likes, retweets = generator.generate_fake_twitter_data(user_count=n, tweets_per_user=1)\n",
    "\n",
    "# Run the asynchronous streaming simulation\n",
    "asyncio.run(simulate_streaming(tweets, users, session, num_tweets=n))"
   ]
  },
  {
   "cell_type": "code",
   "id": "88a76095-77dc-4476-a70b-b5380bfd5e09",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "-- ALTER TASK tweet_processing SUSPEND;\n",
   "execution_count": null
  }
 ]
}